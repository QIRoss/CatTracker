{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QIRoss/CatTracker/blob/main/Proj_Integrado_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "<br>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> 🚀 notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://discord.gg/n6cFeSPZdD\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdLp8WcEzFOQ"
      },
      "source": [
        "# Keep-alive Script\n",
        "\n",
        "\"Keep-alive Script\" to prevent **inactivity timeouts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "-Wvgl1coHJjv",
        "outputId": "eaf65fdb-5299-4688-eab3-3c4611e81ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kept alive.\n",
            "Kept alive.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-64f3ba17bd29>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to keep alive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        requests.get('https://www.google.com')\n",
        "        print(\"Kept alive.\")\n",
        "    except:\n",
        "        print(\"Failed to keep alive.\")\n",
        "    time.sleep(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "6d6303ef-a4f6-47bf-ba61-0ec2860b64c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 🚀 v7.0-242-gb378d10 Python-3.10.12 torch-2.1.0+cu118 CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.9/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgQFI8OejQyq"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/catfinder-train-data-v4.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izfFwOVGRau4"
      },
      "source": [
        "# 2. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "5ce39926-5eee-4434-efdb-7a5dbc40fa61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-19 07:34:16.015468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-19 07:34:16.015540: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-19 07:34:16.015607: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/catfinder-train-data-v4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-242-gb378d10 Python-3.10.12 torch-2.1.0+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 54.6MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/catfinder-train-data-v4/train/labels... 1292 images, 0 backgrounds, 0 corrupt: 100% 1292/1292 [00:01<00:00, 1244.10it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/catfinder-train-data-v4/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100% 1292/1292 [00:27<00:00, 47.68it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/catfinder-train-data-v4/valid/labels... 670 images, 0 backgrounds, 0 corrupt: 100% 670/670 [00:01<00:00, 582.52it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/catfinder-train-data-v4/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.6GB ram): 100% 670/670 [00:16<00:00, 41.52it/s] \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.14 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29         0G    0.08473    0.02968          0         34        640: 100% 81/81 [30:56<00:00, 22.92s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [04:50<00:00, 13.83s/it]\n",
            "                   all        670        780      0.136       0.49      0.121     0.0373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29         0G    0.05639    0.02336          0         37        640:  73% 59/81 [22:51<08:33, 23.33s/it]"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5 for X epochs\n",
        "!python train.py --img 640 --batch 16 --epochs 30 --data /content/catfinder-train-data-v4/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 3. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ZbuQCH7FX",
        "outputId": "0fbf8c83-0291-4191-8898-1299eaaf6399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/last.pt'], source=/content/video-test-cats.mp4, data=data/coco128.yaml, imgsz=[720, 720], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "WARNING ⚠️ --img-size [720, 720] must be multiple of max stride 32, updating to [736, 736]\n",
            "video 1/1 (1/7514) /content/video-test-cats.mp4: 416x736 (no detections), 44.1ms\n",
            "video 1/1 (2/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (3/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (4/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (5/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (6/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (7/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (8/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (9/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.0ms\n",
            "video 1/1 (10/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.0ms\n",
            "video 1/1 (11/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (12/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (13/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (14/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (15/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (16/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (17/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (18/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (19/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.6ms\n",
            "video 1/1 (20/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (21/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.3ms\n",
            "video 1/1 (22/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (23/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (24/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (25/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (26/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (27/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (28/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (29/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (30/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (31/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (32/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.0ms\n",
            "video 1/1 (33/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (34/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (35/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (36/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (37/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.5ms\n",
            "video 1/1 (38/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (39/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (40/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (41/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (42/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (43/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (44/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (45/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (46/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (47/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (48/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (49/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.3ms\n",
            "video 1/1 (50/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (51/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (52/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (53/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (54/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (55/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (56/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (57/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (58/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (59/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (60/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (61/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (62/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (63/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (64/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (65/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (66/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (67/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (68/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (69/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (70/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.4ms\n",
            "video 1/1 (71/7514) /content/video-test-cats.mp4: 416x736 (no detections), 7.1ms\n",
            "video 1/1 (72/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (73/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (74/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.1ms\n",
            "video 1/1 (75/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (76/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (77/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (78/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (79/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (80/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (81/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (82/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (83/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (84/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (85/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (86/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (87/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (88/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (89/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (90/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.8ms\n",
            "video 1/1 (91/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (92/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (93/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (94/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (95/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (96/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (97/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (98/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (99/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.8ms\n",
            "video 1/1 (100/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (101/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (102/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (103/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (104/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (105/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (106/7514) /content/video-test-cats.mp4: 416x736 (no detections), 6.9ms\n",
            "video 1/1 (107/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (108/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (109/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.2ms\n",
            "video 1/1 (110/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (111/7514) /content/video-test-cats.mp4: 416x736 1 cat, 7.1ms\n",
            "video 1/1 (112/7514) /content/video-test-cats.mp4: 416x736 1 cat, 6.9ms\n",
            "video 1/1 (113/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.1ms\n",
            "video 1/1 (114/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.1ms\n",
            "video 1/1 (115/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.0ms\n",
            "video 1/1 (116/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.1ms\n",
            "video 1/1 (117/7514) /content/video-test-cats.mp4: 416x736 2 cats, 8.2ms\n",
            "video 1/1 (118/7514) /content/video-test-cats.mp4: 416x736 2 cats, 8.4ms\n",
            "video 1/1 (119/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.4ms\n",
            "video 1/1 (120/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.4ms\n",
            "video 1/1 (121/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.4ms\n",
            "video 1/1 (122/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.7ms\n",
            "video 1/1 (123/7514) /content/video-test-cats.mp4: 416x736 2 cats, 8.7ms\n",
            "video 1/1 (124/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.7ms\n",
            "video 1/1 (125/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.7ms\n",
            "video 1/1 (126/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.7ms\n",
            "video 1/1 (127/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.9ms\n",
            "video 1/1 (128/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.9ms\n",
            "video 1/1 (129/7514) /content/video-test-cats.mp4: 416x736 1 cat, 8.9ms\n",
            "video 1/1 (130/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.9ms\n",
            "video 1/1 (131/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.9ms\n",
            "video 1/1 (132/7514) /content/video-test-cats.mp4: 416x736 (no detections), 8.9ms\n",
            "video 1/1 (133/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.1ms\n",
            "video 1/1 (134/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.1ms\n",
            "video 1/1 (135/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.0ms\n",
            "video 1/1 (136/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.1ms\n",
            "video 1/1 (137/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.1ms\n",
            "video 1/1 (138/7514) /content/video-test-cats.mp4: 416x736 1 cat, 9.1ms\n",
            "video 1/1 (139/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (140/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (141/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "video 1/1 (142/7514) /content/video-test-cats.mp4: 416x736 (no detections), 9.1ms\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 131, in run\n",
            "    pred = model(im, augment=augment, visualize=visualize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 527, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 324, in forward\n",
            "    return torch.cat(x, self.d)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 287, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 282, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/detect.py\", line 129, in run\n",
            "    with dt[1]:\n",
            "  File \"/content/yolov5/utils/general.py\", line 194, in __exit__\n",
            "    self.dt = self.time() - self.start  # delta-time\n",
            "  File \"/content/yolov5/utils/general.py\", line 199, in time\n",
            "    torch.cuda.synchronize()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 688, in synchronize\n",
            "    return torch._C._cuda_synchronize()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights runs/train/exp/weights/last.pt --img 720 --conf 0.4 --source /content/video-test-cats.mp4  --save-crop --save-txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaKQsVZvhloo"
      },
      "source": [
        "# 4. Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "## Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Notebooks** with free GPU: <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a> <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "## Status\n",
        "\n",
        "![YOLOv5 CI](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on macOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "## Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "outputs": [],
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}